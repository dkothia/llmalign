# LLMAlign.ai: Enterprise LLM Fine-Tuning & Deployment Platform

LLMAlign.ai is a full-stack SaaS platform designed for enterprises to **fine-tune, deploy, and manage large language models (LLMs)** on domain-specific data securely and efficiently.

---

## Features

- Fine-tune LLMs using **LoRA** for cost-efficient adaptation
- Deploy models as APIs for internal applications
- Supports multiple data sources: PDFs, databases


---

## Folder Structure
```s
llmalign/
├── llmalign_be/
│   ├── app/
│   │   ├── models/
│   │   │   └── schemas.py
│   │   ├── routers/
│   │   │   ├── predict.py
│   │   │   ├── train.py
│   │   │   └── upload.py
│   │   ├── services/
│   │   │   ├── predictor.py
│   │   │   ├── s3_utils.py
│   │   │   └── trainer.py
│   │   ├── tests/
│   │   │   ├── test_predict.py
│   │   │   └── test_s3.py
│   │   └── utils/
│   │       └── file_parser.py
│   ├── models/
│   ├── results/
│   └── venv/
├── llamalign_fe/
│ ├── src/
│ │ ├── App.js
│ │ └── index.js
│ ├── package.json
├── README.md
├── .gitignore
```

---

## Setup Instructions

### Backend (FastAPI)

1. Navigate to the backend folder:
```s
  cd llmalign_be
```

2. Create and activate a virtual environment:
```s
  python -m venv .venv
  source .venv/bin/activate   # Mac/Linux
  .venv\Scripts\activate      # Windows
```

3. Install dependencies:
   ```s
   pip install -r requirements.txt
   ```

4. Run the FastAPI server:
   ```s
   uvicorn app.main:app --reload
   ```

### Frontend (React.js)

1. Navigate to the frontend folder:
   ```s
   cd llmalign_fe
   ```
   
2. Install dependencies:
   ```s
   npm install
   ```

3. Start the development server:
   ```s
   npm start
   ```

App will be available at http://localhost:3000
   



















